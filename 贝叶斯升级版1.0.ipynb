{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 贝叶斯统计\n",
    "\n",
    "## 1.机器学习概论\n",
    "\n",
    "我们自己本身就是在以往经验中推断事物发展的潜在规律。而这些，实际上计算机也可以通过学习历史数据，来获得可能的潜在规律，然后据此，输入现在的数据，来预测未来可能发生\n",
    "不论是什么学习，我们都需要数据。\n",
    "\n",
    "而数据本身用什么描述就很重要。例如：对于一家公司，可以简单到用公司的注册商标就能描述；也可以很复杂到用财报中各种会计项目来综合描述这家公司。然而，我们所描述的对象都是相同的。而我们想要如何描述这个对象，取决于我们想要推断的东西。\n",
    "\n",
    "那么用来描述一个样本本身的信息，我们称之为**属性**。例如：一家公司的固定资产，流动负债，经营现金流量的多少都是这家公司的属性。把这些属性量化之后放入一个样本空间，可以在这之中找到对应的一个坐标。这个坐标就对应了这个样本空间中唯一的向量，这个就是**特征向量**，每一个特征向量也和每一个样本一一对应。之所以如此表示是因为如果想要更好的接近潜在的真实规律需要足够多的属性，而向量和计算机的搭配在处理这方面有很好的效果。\n",
    "\n",
    "计算机从数据中获得模型的过程就是**学习**（或者**训练**）。用于训练的样本就是**训练样本**，组成的集合就是**训练集**。然而由于我们不可能穷尽总体，且无法获取总体确定的参数，所以学习得到的模型我们叫**假设**。然而我们之所以可以把学来的的模型直接用来预测，在于我们的目的是在基于现在来预测未来，那么我们获取的历史数据实际上就可以看成一次随机抽样。那么理论上，我们通过样本估计的参数（且估计方法得当）那么是可以用于逼近总体参数的。总体的规律我们会称为**真相**。\n",
    "\n",
    "光有数据还是不够的。例如：我们们想要判断西瓜是否是一个好瓜，我们除了得到训练样本，还要有训练样本的“**结果**”信息。一个瓜有，色泽=青绿；根蒂=蜷缩；敲声=浑浊，结果发现这是个好瓜。这个“好瓜”我们称之为**标记**。这样我们就可以定已**样例**：\n",
    "\n",
    "$$(x_i,y_i)$$\n",
    "\n",
    "其中，$x_i$是一个来自训练集的一个特征向量，$y_i \\in Y$是一个标记，$Y$是所有标记的集合。\n",
    "\n",
    "基于数据的分类，我们的学习方式也不同。\n",
    "\n",
    "对于离散的数据，这类学习任务称作**分类**；对于连续型（这里连续并不是指的数学严格意义的连续，实际上是数值的个数一般都是可数的），这类任务我们称作**回归**。我们主要讨论分类。\n",
    "\n",
    "对于只有两个类别，就称之为二分类。一个称之为“正类”，另一个称之为“反类”。例如：西瓜的好坏就是一个典型的二分类。当涉及多个类别的时候，就将其称之为多分类任务。\n",
    "\n",
    "通常来讲，预测就是通过对{$(x_1,y_1),(x_2,y_2),...,(x_n,y_n)$}进行学习，建立一个从**输入空间**$X$到分类空间$Y$的映射关系。\n",
    "\n",
    "二分类$Y$量化一般会用{0，1}，而多分类Y一般会取$N$的真子集。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.贝叶斯决策论\n",
    "\n",
    "贝叶斯决策论是在概率框架下实施决策的基本方法。对分类任务来说，在所有相关概率都已知的情况下，如何基于**概率和误判损失**来选择最优的的类别标记。\n",
    "\n",
    "而我们决策的思想就是找到一个标签最大后验概率对应的一条特征向量。下面的论述逻辑顺序是参考《机器学习》（不少人称之为西瓜书），但在《统计学习方法》中，作者给出了关于分类风险最小化与后验概率最大化等价的详细证明：\n",
    "\n",
    "证明：\n",
    "\n",
    "定义损失函数$L(Y,f(x))$，Y是所有标签构成的集合，$f（x）$就是一个贝叶斯分类器，输入一个特征向量，会得到在训练过后**计算机认为正确的标签**（潜台词就是这个和真实的标签有可能不一样！！！！）\n",
    "\n",
    "$$\n",
    "L(Y,f(x))=\\begin{cases}1&Y=f(x)\\\\0&Y\\neq {f(x)}\\end {cases}\n",
    "$$\n",
    "\n",
    "这时损失的期望有\n",
    "\n",
    "$$\n",
    "R_{exp}(f)=E[L(Y,f(x))]\n",
    "$$\n",
    "1）\n",
    "\n",
    "该期望是对$P（X，Y）$联合分布取的（**注意这里没有添加朴素贝叶斯的假设！**），所以\n",
    "\n",
    "$$\n",
    "R_{exp}(f)=\\sum_YL(Y,f(x))P(Y|X)\n",
    "$$\n",
    "2）\n",
    "\n",
    "注意，这里Y你可能取到正确的，也可能取到不正确的——这时候就体现出来损失函数设计的巧妙了，因为假如你去到正确的，那么取值和概率相乘为零，而取到不正确的，则式子最后实际上变得简单很多。为了使期望风险最小化，那么就要使得$P（Y|X）$最小化，那么我们将最小化（2）做一个更清楚的表达\n",
    "\n",
    "$$\n",
    "f(x)=\\underset {y\\in Y}{argmin}\\sum_{k=1}^{K}L(y_k,f(x))P(c_k|X=x)\n",
    "$$\n",
    "3)\n",
    "\n",
    "$y_k$就是Y中的第$k$个标签，$x$是某一个特征向量\n",
    "\n",
    "这样事情就具体了，我们对每一个x都最小化就可以了，假设$y_0$是实际情况下真实的标签\n",
    "\n",
    "（3）=\n",
    "\n",
    "$$\n",
    "\\underset {y\\in Y}{argmin}\\sum_{k=1}^{K}P(y\\neq y_0|X=x)\n",
    "$$\n",
    "$$\n",
    "=\\underset {y\\in Y}{argmin}(1-P(y=y_0|X=x))\n",
    "$$\n",
    "$$\n",
    "=\\underset {y\\in Y}{argmax}\\sum_{k=1}^{K}P(y=y_0|X)\n",
    "$$\n",
    "\n",
    "证毕"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. 分类\n",
    "\n",
    "分类有二分类和多分类。而实际情况中我们遇到的更多的是多分类。然而，多分类实际上是有着广泛的应用。因为这个世界本身非黑即白的事情就非常少，更不用说在金融的世界里。但是多分类对于只认0和1的计算机相对来说还是复杂太多了。\n",
    "\n",
    "实际解决问题中，多分类实际上可以通过拆分成二分类的方式来完成。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 例2.1.1 对于工资高低影响因素的分析\n",
    "\n",
    "我们每天都可以从各个渠道的到消息。投资者们也是基于今天的信息预测未来。那么该怎怎么让计算机也能有基于现在的信息预测一下未来呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据来源于伍德里奇的计量经济学的数据集wage2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>wage</th>\n",
       "      <th>hours</th>\n",
       "      <th>IQ</th>\n",
       "      <th>KWW</th>\n",
       "      <th>educ</th>\n",
       "      <th>exper</th>\n",
       "      <th>tenure</th>\n",
       "      <th>age</th>\n",
       "      <th>married</th>\n",
       "      <th>black</th>\n",
       "      <th>south</th>\n",
       "      <th>urban</th>\n",
       "      <th>sibs</th>\n",
       "      <th>brthord</th>\n",
       "      <th>meduc</th>\n",
       "      <th>feduc</th>\n",
       "      <th>lwage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>769</td>\n",
       "      <td>40</td>\n",
       "      <td>93</td>\n",
       "      <td>35</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.645091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>808</td>\n",
       "      <td>50</td>\n",
       "      <td>119</td>\n",
       "      <td>41</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.694562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>825</td>\n",
       "      <td>40</td>\n",
       "      <td>108</td>\n",
       "      <td>46</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.715384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>650</td>\n",
       "      <td>40</td>\n",
       "      <td>96</td>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.476973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>562</td>\n",
       "      <td>40</td>\n",
       "      <td>74</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.331502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  wage  hours   IQ  KWW  educ  exper  tenure  age  married  \\\n",
       "0           1   769     40   93   35    12     11       2   31        1   \n",
       "1           2   808     50  119   41    18     11      16   37        1   \n",
       "2           3   825     40  108   46    14     11       9   33        1   \n",
       "3           4   650     40   96   32    12     13       7   32        1   \n",
       "4           5   562     40   74   27    11     14       5   34        1   \n",
       "\n",
       "   black  south  urban  sibs  brthord  meduc  feduc     lwage  \n",
       "0      0      0      1     1      2.0    8.0    8.0  6.645091  \n",
       "1      0      0      1     1      NaN   14.0   14.0  6.694562  \n",
       "2      0      0      1     1      2.0   14.0   14.0  6.715384  \n",
       "3      0      0      1     4      3.0   12.0   12.0  6.476973  \n",
       "4      0      0      1    10      6.0    6.0   11.0  6.331502  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "info=pd.read_csv('wage2.csv')\n",
    "info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(935, 18)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要注意这些数据并不是都是属性。实际上我们现实中的信息有很多并不能解释我们的因果关系。这就有一个**信噪比**的概念。即样例中信息于白噪声的比例（我们并不需要知道这个比例是什么）。我们是社会科学的数据分析，无法通过控制实验进而使得获得的信息纯度非常高的数据，这尤其需要我们通过经济学金融学知识来做合理的假设。合理的假设将使得分析的结论更加有说服力，逻辑更严谨；对于机器学习来说，预测的结果质量也会更高。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回到我们的工资。我们人能够预测是因为我们从经验中学习到了规律，那么这个放在计算机中，用数学的方式表达就是：\n",
    "\n",
    "$$wage=f(tenure,age,urban,educ,black)$$（1）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们看到，（1）就是一个回归。但要注意的是，回归和分类虽然没有本质上的区别，但是朴素贝叶斯学习器主要用于做的就是分类，区别在于标签（因变量）是足够分散的。例子中的工资是一个整数集，而这个整数太标签太多了，可能出现这样的情况：总体中有工资为400的人，但是训练样本中没有！这样的学习就是无意义的！而且还有这样的情况，400的出现次数太少了，而且你还需要401和399的样本出现次数足够多，才能得出一个可靠的工资为400的情况的概率分布。上面说的情况其实就算是标签足够离散也可能会发生，但本来是可以做回归的数据何必要选择一个错误率很高的方法预测呢？\n",
    "\n",
    "所以，朴素贝叶斯不是万能的，而机器学习更不是数据分析的全部。**机器学习并不是万能的。**\n",
    "\n",
    "后面会给一个多分类的例子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 例 2.1.2 一个二分类：选西瓜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在搞清楚多分类之前，需要先明白什么是二分类。实际上，之后的多分类也是由二分类的思想发展而来的。对于只有两个类别，就称之为二分类。一个称之为“正类”，另一个称之为“反类”。例如：西瓜的好坏就是一个典型的二分类。其实这就是通过既有信息判断对错的一个方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>色泽</th>\n",
       "      <th>根蒂</th>\n",
       "      <th>敲声</th>\n",
       "      <th>纹理</th>\n",
       "      <th>脐部</th>\n",
       "      <th>触感</th>\n",
       "      <th>密度</th>\n",
       "      <th>含糖率</th>\n",
       "      <th>好瓜</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>编号</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>青绿</td>\n",
       "      <td>蜷缩</td>\n",
       "      <td>浊响</td>\n",
       "      <td>清晰</td>\n",
       "      <td>凹陷</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.460</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>乌黑</td>\n",
       "      <td>蜷缩</td>\n",
       "      <td>沉闷</td>\n",
       "      <td>清晰</td>\n",
       "      <td>凹陷</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.376</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>乌黑</td>\n",
       "      <td>蜷缩</td>\n",
       "      <td>浊响</td>\n",
       "      <td>清晰</td>\n",
       "      <td>凹陷</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.264</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>青绿</td>\n",
       "      <td>蜷缩</td>\n",
       "      <td>沉闷</td>\n",
       "      <td>清晰</td>\n",
       "      <td>凹陷</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.318</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>浅白</td>\n",
       "      <td>蜷缩</td>\n",
       "      <td>浊响</td>\n",
       "      <td>清晰</td>\n",
       "      <td>凹陷</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.215</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    色泽  根蒂  敲声  纹理  脐部  触感     密度    含糖率 好瓜\n",
       "编号                                         \n",
       "1   青绿  蜷缩  浊响  清晰  凹陷  硬滑  0.697  0.460  是\n",
       "2   乌黑  蜷缩  沉闷  清晰  凹陷  硬滑  0.774  0.376  是\n",
       "3   乌黑  蜷缩  浊响  清晰  凹陷  硬滑  0.634  0.264  是\n",
       "4   青绿  蜷缩  沉闷  清晰  凹陷  硬滑  0.608  0.318  是\n",
       "5   浅白  蜷缩  浊响  清晰  凹陷  硬滑  0.556  0.215  是"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'https://raw.githubusercontent.com/han1057578619/MachineLearning_Zhouzhihua_ProblemSets/master/data/watermelon3_0_Ch.csv').set_index('编号')\n",
    "df.head()#获取并显示样本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以通过训练发现一些特征使得预测样本标记为“好瓜”的概率更大，那么就完成了训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多分类学习中，通常可以分为三种拆分成二分类的方式：“一对一”，“一对余”，“多对多”\n",
    "\n",
    "给定一个数据集$D=${$(x_i,y_i)|i=1,2,3,..,n$}，$y_i\\in Y$, $Y=${$C_i|i-1,2,3,4,...,n$}\n",
    "\n",
    "一对一是将里面的特征两两配对，分别设置为正分类和反分类，产生$C^2_n=\\frac{n(n-1)}{2}$个分类器，然后将新的样本提交给这些分类器，的到和分类器同样多的分类结果，最后取众数分类结果作为该样本的标签。\n",
    "\n",
    "一对多则是将所有标签中挑选一个作为正分类，其他的标签作为反分类。这样的到的分类器就有$C^2_n=\\frac{1}{n}$个分类器。理论上，预测为正类的分类器应该只有一个，然而并不是不会出现多个分类器出现了正类的结果，此时就对所有出现正类的分类器预测置信度进行评估，选出最可靠的标签作为分类结果。\n",
    "\n",
    "而多对多实际上就是将一部分的标签归为正类，一部分标签归为反类。显然，一对一和一对多实际上就是多对多的两种特殊情况。而划分是不能随意划分的。\n",
    "\n",
    "下面提供一种常用的划分方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.1.2纠错输出码方法\n",
    "这个方法思路并不复杂。首先将N个标签进行M次的正反类划分，这样就可以训练出M个二分类分类器。用一组测试样例分别对这M组分类器进行测试，选择输出标签与测试样本误差最小的那一个二分类器作为多对多的分类方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.在概率的思想下进行分类：贝叶斯分类器\n",
    "\n",
    "以多分类举例。\n",
    "\n",
    "在现实生活中，我们难免出现分类错误的情况。这个的原因来源可能有两个：样例的偏差和我们的假设的问题。对于计算机也是一样的。当我们训练集和我们想要逼近的总体有偏差时，训练出来的分类器本身就会分类错误。而由于总体参数本身的不可得性质我们得分类器只能逼近真相，使得我们预测得时候不可避免产生误差。\n",
    "\n",
    "而这些误差在现实生活中会给我们造成损失。尤其在基本都是零和博弈的金融市场，分类错误将势必导致我们的损失。而贝叶斯分类器的思想就是找到期望损失最小的那个分类器。\n",
    "\n",
    "现在有一个样本空间 \n",
    "$$X=(x_1,x_2,x_3,...,x_n)$$\n",
    "\n",
    "$x$ 是样本空间中的特征向量\n",
    "\n",
    "假设有N种可能的类别标记，记为\n",
    "\n",
    "$$Y={c_1,c_2,c_3,...,c_N}$$\n",
    "\n",
    "设$\\lambda_{ij}$是将一个真实标记为$c_j$的样本误分类为$c_i$所产生的损失的总和。基于后验概率$P(c_i|x)$(可以理解为把样本x分类为$c_i$的概率)\n",
    "\n",
    "那么可以定义**分类风险** \n",
    "$$R(c_i|x)=\\underset{j=1}{\\overset{N}{\\sum}}\\lambda_{ij}P(c_j|x)$$\n",
    "\n",
    "这样我们就有一个分类器$S(x)$总体风险的定义\n",
    "\n",
    "$$R(s)=E_x[R(S(x)|x)]$$\n",
    "\n",
    "而我们是想找到一个总体风险最小化的一个分类器$S^*(x)$，使得，\n",
    "\n",
    "$$R(S^*)=argminE_x[R(S^*(x)|x)]$$\n",
    "\n",
    "这里$S(x)$是变化的，给定$x$的含义是在于我的训练样本是完全没有变化的。\n",
    "\n",
    "这里，$S^*(x)$被称作贝叶斯最优分类器。$R(S^*)$被称作贝叶斯风险。而$1-R(S^*)$反映了分类器可以达到的最好性能，即理论上机器学习后产生的模型的最高精度上限。\n",
    "\n",
    "此时$\\lambda_{ij}$就是一个随机变量，分布列为\n",
    "\n",
    "|$\\lambda_{ij}$|1|0|\n",
    "|:---:|:---:|:---:|\n",
    "|P|$P(i\\neq j)$|$P(i=j)$|\n",
    "\n",
    "此时分类风险就可以写成，\n",
    "$$R(c|x)=1-P(c|x)$$\n",
    "\n",
    "此时，贝叶斯最优分类器为，\n",
    "\n",
    "$$S^*(x)=\\underset{c\\in Y}{argmin}P(c|x)$$\n",
    "\n",
    "所以，可以看出，如果要得到精度最高的分类器，则要选择使后验概率最高的类别标记。\n",
    "\n",
    "这个逻辑是参考《机器学习》(西瓜书)，之前在贝叶斯决策论部分已经有了比较完整的数学证明。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3.1贝叶斯定理和朴素贝叶斯：\n",
    "\n",
    "$$P(c|x)=\\frac {P(c)P(x|c)}{P(x)}$$\n",
    "\n",
    "其中，$P(c)$是类别的先验概率；$P(x|c)$是样本相对于类标记c的条件概率，也叫做似然概率（可以理解为x被标记为c类别的概率）；而$P(x)$是用于归一化的“证据因子”（**实际上我们后面得到的贝叶斯分类器是不考虑这个P（x）的。因为这个统一除以P（x）实际上是向概率的三大条件做了妥协。此处我们目的就是对各个标签对应各个特征来打分而已**）。对给定的样本$x$,证据因子与类标记是无关的。因此获得贝叶斯分类器就变成了如何基于训练集来估计先验概率$P(c)$和$P(x|c)$。\n",
    "\n",
    "贝叶斯分类器在训练中最大困难就是就是后验概率$P(c|x)$中属性上的联合分布很难从有限的样本里面估计得到。为了能够简化过程，所以有一个强假设就是各个属性条件都是相互独立的（这也是将这个方法称之为***朴素*贝叶斯的原因**），即将在所有已知的分类情况下，所有属性都是独立的，属性对于类别影响是独立的。那么，贝叶斯定理可写成，\n",
    "$$P(c|x)=\\frac{P(c)P(x|c)}{P(x)}=\\frac{P(c)}{P(x)}\\overset{d}{\\underset{i=1}{\\prod}} P(x_i|c)$$\n",
    "其中d为属性数目，$x_i$为$x$在第$i$个属性上的取值\n",
    "\n",
    "对于所有类别来说，$P(x)$都是相同的，所以最优贝叶斯分类器就有，\n",
    "$$S^*(x)=argmaxP(c)\\overset{d}{\\underset{i=1}{\\prod}}P(x_i|c)$$\n",
    "这就是朴素贝叶斯分类器的表达式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "朴素贝叶斯分类器也就变成了求两个部分：先验概率和似然概率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 先验概率的估计"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "类概率$P(c)$表示了所有样例中各类样例所占的比例。根据大数定律，当我们的样例足够多的时候，各类样例出现频率收敛于概率。因此可以通过各类别出现的频率来估计类概率。\n",
    "下面给出代码的实现，例子使用选瓜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>色泽</th>\n",
       "      <th>根蒂</th>\n",
       "      <th>敲声</th>\n",
       "      <th>纹理</th>\n",
       "      <th>脐部</th>\n",
       "      <th>触感</th>\n",
       "      <th>密度</th>\n",
       "      <th>含糖率</th>\n",
       "      <th>好瓜</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>编号</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>青绿</td>\n",
       "      <td>蜷缩</td>\n",
       "      <td>浊响</td>\n",
       "      <td>清晰</td>\n",
       "      <td>凹陷</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.460</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>乌黑</td>\n",
       "      <td>蜷缩</td>\n",
       "      <td>沉闷</td>\n",
       "      <td>清晰</td>\n",
       "      <td>凹陷</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.376</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>乌黑</td>\n",
       "      <td>蜷缩</td>\n",
       "      <td>浊响</td>\n",
       "      <td>清晰</td>\n",
       "      <td>凹陷</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.264</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>青绿</td>\n",
       "      <td>蜷缩</td>\n",
       "      <td>沉闷</td>\n",
       "      <td>清晰</td>\n",
       "      <td>凹陷</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.318</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>浅白</td>\n",
       "      <td>蜷缩</td>\n",
       "      <td>浊响</td>\n",
       "      <td>清晰</td>\n",
       "      <td>凹陷</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.215</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    色泽  根蒂  敲声  纹理  脐部  触感     密度    含糖率 好瓜\n",
       "编号                                         \n",
       "1   青绿  蜷缩  浊响  清晰  凹陷  硬滑  0.697  0.460  是\n",
       "2   乌黑  蜷缩  沉闷  清晰  凹陷  硬滑  0.774  0.376  是\n",
       "3   乌黑  蜷缩  浊响  清晰  凹陷  硬滑  0.634  0.264  是\n",
       "4   青绿  蜷缩  沉闷  清晰  凹陷  硬滑  0.608  0.318  是\n",
       "5   浅白  蜷缩  浊响  清晰  凹陷  硬滑  0.556  0.215  是"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'https://raw.githubusercontent.com/han1057578619/MachineLearning_Zhouzhihua_ProblemSets/master/data/watermelon3_0_Ch.csv').set_index('编号')\n",
    "df.head()#获取并显示样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们的算法是这样的：\n",
    "\n",
    "既然我们是想用大数定理，用大样本的频率逼近概率，那么实际上我们要算的每一个$P（c）$就算每一个标签在样本中的频率即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_num,fea_num=df.shape[0],df.shape[1]-1#数据给的是样例，所以要把标签去掉\n",
    "dis_fea_name,con_fea_name,ylabel=['色泽','根蒂','敲声','纹理','脐部','触感'],['密度','含糖率'],'好瓜'\n",
    "#这里确认了我们的属性和标签"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面计算我们的先验概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pri_prob(ylabel,laplacian=False):\n",
    "    labels=df[ylabel]\n",
    "    label_num=labels.unique()\n",
    "    prior_prob={class_:(len(labels[labels==class_])+1*laplacian)/(sam_num+laplacian*len(label_num)) for class_ in label_num}\n",
    "    return prior_prob\n",
    "#这里我们的输出值是字典"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 拉普拉斯修正\n",
    "贝叶斯分类器有一个问题：因为最后算出的后验概率是一个乘积，也就是说，如果先验概率或者似然概率任何一个有一个值为零，那么从数学的角度我们的后验概率就没有任何意义了。为了使后验概率不为零（**不然你咋打分啊喂**），所以就针对先验概率可能为零的情况，做一个修正"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 对似然概率的估计：极大似然估计\n",
    "\n",
    "极大似然估计有一个很重要的前提假设是已知类条件概率背后的概率分布形式，再基于训练样本对概率分布的参数进行估计。假设$P(x|c)$具有形式可被解析且参数向量$\\theta_c=(\\theta_1,\\theta_2,..,\\theta_n)$唯一唯一确定。现在，我们记$P(x|c)$为$P(x|\\theta_c)$\n",
    "\n",
    "概率模型的训练过程本身就是对模型参数的估计。对于参数的估计统计学中分出了两种学派：频率学派和贝叶斯学派。\n",
    "\n",
    "频率学派和贝叶斯学派思想差异在于频率学派认为参数未知但是固定，而贝叶斯学派认为参数存在但是本身是个随机变量，服从一个一定的分布，那么按照贝叶斯学派的思路，可以假定参数服从某一先验分布，然后基于观测得到的。这两种学派在估计参数上并没有绝对的优劣之分，要看情况而定。\n",
    "\n",
    "两个学派有很多在方法上有很多相似之处，但本质其实也很大区别（**对总体的假设有着根本的去别！**）如果想要通俗的理解，那么就用一个很简单的比喻：假如说你在玩一个套圈的游戏，圈是你的样本，而已知分布类型的未知参数就是你想套中的标志，那么概率学派是希望你的圈能尽可能套中那个标志，标志是固定的；贝叶斯派则是把圈撒出去，然后让标志尽可能落在圈里面，圈撒出去的位置本身是随机的，而标志落点也变成随机的了。但最后的结果都是希望能够让标志在圈中。所以虽然两种方法本质上不同但是你无法评价绝对的好坏。如果会扔圈那么概率派的方法更合适，如果更会投掷标志那么贝叶斯更合适，所以在做拟合和预测的时候，要根据情况去建模选择方法。\n",
    "\n",
    "而这里极大似然估计实际上是典型的频率学派用于估计参数的方式。\n",
    "\n",
    "令$D_c$表示c类样本组成的训练集，假设这些样本是**独立同分布的（随机抽样得到）**，那么就是去寻找最大化$P(D_C|\\theta_c)$的参数值$\\hat{\\theta_c}$\n",
    "$$P(D_c|\\theta_c)=\\underset{x\\in D_c}{\\prod}P(x|\\theta_c)$$\n",
    "$$maxP(D_c|\\theta_c)=\\underset{x\\in D_c}{\\prod}P(x|\\hat{\\theta_c})$$\n",
    "\n",
    "这里之所以能够将函数拆分成乘积的形式依赖于一个很重要的假设就是这些样本都是独立同分布的。也就是说这些样本获取的方式必须是简单随机抽样。对于似然函数具体求解方法可以参考《概率论与数理统计》。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面计算似然概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#和上面计算先验概率我们也通过定义函数输出一个字典\n",
    "def likehood(dis_fea_name,con_fea_name,ylabel,laplacian=False):\n",
    "    con_contg_prob={}\n",
    "    dis_contg_prob={}\n",
    "    def func(con_mean,con_std):\n",
    "        return lambda x: stats.norm.pdf(x,con_mean,con_std)\n",
    "    #计算离散的条件概率\n",
    "    labels=df[ylabel].unique()\n",
    "    for name in dis_fea_name: #遍历所有的属性\n",
    "        for label in labels:#遍历所有标签\n",
    "            for fea_value in df[name].unique():#遍历所有特征\n",
    "                tem_df=df.loc[:,[name,ylabel]]\n",
    "                contg_prob=(len(tem_df[(tem_df[name]==fea_value)&(tem_df[ylabel]==label)])+laplacian*1)/ \\\n",
    "                (len(tem_df[(tem_df[ylabel]==label)])+laplacian*len(df[name].unique()))\n",
    "                dis_contg_prob[name+fea_value+label]=contg_prob\n",
    "    #计算连续的条件概率\n",
    "    for name in con_fea_name:\n",
    "        for label in labels:\n",
    "            tem_df=df.loc[:,[name,ylabel]]\n",
    "            con_mean=tem_df[tem_df[ylabel]==label].mean()[0]\n",
    "            con_std=tem_df[tem_df[ylabel]==label].std()[0]\n",
    "            con_contg_prob[name+label]=func(con_mean,con_std)\n",
    "    return dis_contg_prob,con_contg_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们要注意一个很重要的地方：func（con_mean,con_std）的定义。这里并不是需要注意这个函数到底是想输入什么然后输出什么（如果不理解那么还是解释一下吧：对于离散型的属性（就是随机变量），我们要求似然函数然后得到一个分布列（我们看到分布列是可以通过取值查询到一个唯一对应的概率，所以我们会想输出为一个字典，至于为什么不是列表或者元组这种实际上也可以查询的东西，很简单。因为属性和特征在这都有很重要的意义）），而离散型我们就是需要一个密度函数。\n",
    "\n",
    "那么问题来了做似然估计的时候，是一定要假设好服从的分布类型的！那么这样就来到了开始的问题：我们要设置什么分布？\n",
    "\n",
    "很显然这里我们是选取了正态分布，逻辑是认为这个数据量是符合中心极限定理的\n",
    "\n",
    "$$\\lim_{n\\to \\infty}（\\tfrac{\\sum_{i=1}^{n}X_i-n\\mu}{\\sqrt{n}\\sigma}\\leq{x}）服从N(0,1)$$\n",
    "\n",
    "这个的意思是，当样本容量足够大，且独立同分布（**随机抽样**）情况下，随机变量的分布会趋近正态分布\n",
    "\n",
    "而实际上，现实中当$n\\geq30$其实就已经可以很好拟合正态分布了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "记下来就可以得到贝叶斯分类器了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes_class(dis_fea_name,con_fea_name,ylabel,laplacian=False):\n",
    "    prior_probability=pri_prob(label,laplacian=False)\n",
    "    dis_contg_prob,con_contg_prob=likehood(dis_fea_name,con_fea_name,label,laplacian=False)\n",
    "    return prior_probability,dis_contg_prob,con_contg_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当贝叶斯分类器训练出来以后就可以编写预测用函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data,prior_prob,dis_contg_prob,con_contg_prob,):\n",
    "    labels=['是','否']\n",
    "    score={}\n",
    "    for label in labels:\n",
    "        score[label]=prior_prob[label]\n",
    "        for name,value in zip(list(df.columns)[:-1],data):\n",
    "            if type(value)==str:#这里实际上目的是为了判断离散还是连续，这里就是如果是离散的意思\n",
    "               score[label]*=dis_contg_prob[name+value+label] \n",
    "            else:\n",
    "                score[label]*=con_contg_prob[name+label](value)\n",
    "    if score['是']>score['否']:\n",
    "        result='是'\n",
    "    else:\n",
    "        result='否'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'是'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = ['青绿', '蜷缩', '浊响', '清晰', '凹陷', '硬滑', 0.697, 0.460]\n",
    "prior_probability,dis_contg_prob,con_contg_prob=bayes_class(dis_fea_name,con_fea_name,ylabel,laplacian=False)\n",
    "predict(test_data,prior_probability,dis_contg_prob,con_contg_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然而能分开西瓜并不应该满足我们（我们可是将来要赚大钱的金融人啊！）所以这里重新给一个金融例子，来向各位展示金融中贝叶斯的作用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 多分类，用一个微观经济的例子：前面的工资问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "工资由于其连续程度并不适合使用朴素贝叶斯，那么就做点有些有意思的：我们看看什么样的经济条件才能让一个有色人种在城市中生活呢？\n",
    "\n",
    "你可能会说有可能这个有色人种是刚来到城市，这样不是不准确了嘛。然而要一直注意，小概率事件有的，虽然很难发生，在这样随机的情况下我们得到的结论几乎都是统计上的。\n",
    "\n",
    "那么开始编写代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>wage</th>\n",
       "      <th>hours</th>\n",
       "      <th>IQ</th>\n",
       "      <th>KWW</th>\n",
       "      <th>educ</th>\n",
       "      <th>exper</th>\n",
       "      <th>tenure</th>\n",
       "      <th>age</th>\n",
       "      <th>married</th>\n",
       "      <th>black</th>\n",
       "      <th>south</th>\n",
       "      <th>urban</th>\n",
       "      <th>sibs</th>\n",
       "      <th>brthord</th>\n",
       "      <th>meduc</th>\n",
       "      <th>feduc</th>\n",
       "      <th>lwage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>769</td>\n",
       "      <td>40</td>\n",
       "      <td>93</td>\n",
       "      <td>35</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.645091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>808</td>\n",
       "      <td>50</td>\n",
       "      <td>119</td>\n",
       "      <td>41</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.694562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>825</td>\n",
       "      <td>40</td>\n",
       "      <td>108</td>\n",
       "      <td>46</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.715384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>650</td>\n",
       "      <td>40</td>\n",
       "      <td>96</td>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.476973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>562</td>\n",
       "      <td>40</td>\n",
       "      <td>74</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.331502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  wage  hours   IQ  KWW  educ  exper  tenure  age  married  \\\n",
       "0           1   769     40   93   35    12     11       2   31        1   \n",
       "1           2   808     50  119   41    18     11      16   37        1   \n",
       "2           3   825     40  108   46    14     11       9   33        1   \n",
       "3           4   650     40   96   32    12     13       7   32        1   \n",
       "4           5   562     40   74   27    11     14       5   34        1   \n",
       "\n",
       "   black  south  urban  sibs  brthord  meduc  feduc     lwage  \n",
       "0      0      0      1     1      2.0    8.0    8.0  6.645091  \n",
       "1      0      0      1     1      NaN   14.0   14.0  6.694562  \n",
       "2      0      0      1     1      2.0   14.0   14.0  6.715384  \n",
       "3      0      0      1     4      3.0   12.0   12.0  6.476973  \n",
       "4      0      0      1    10      6.0    6.0   11.0  6.331502  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>wage</th>\n",
       "      <th>hours</th>\n",
       "      <th>IQ</th>\n",
       "      <th>KWW</th>\n",
       "      <th>educ</th>\n",
       "      <th>exper</th>\n",
       "      <th>tenure</th>\n",
       "      <th>age</th>\n",
       "      <th>married</th>\n",
       "      <th>black</th>\n",
       "      <th>south</th>\n",
       "      <th>urban</th>\n",
       "      <th>sibs</th>\n",
       "      <th>brthord</th>\n",
       "      <th>meduc</th>\n",
       "      <th>feduc</th>\n",
       "      <th>lwage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>935.00000</td>\n",
       "      <td>935.000000</td>\n",
       "      <td>935.000000</td>\n",
       "      <td>935.000000</td>\n",
       "      <td>935.000000</td>\n",
       "      <td>935.000000</td>\n",
       "      <td>935.000000</td>\n",
       "      <td>935.000000</td>\n",
       "      <td>935.000000</td>\n",
       "      <td>935.000000</td>\n",
       "      <td>935.000000</td>\n",
       "      <td>935.000000</td>\n",
       "      <td>935.000000</td>\n",
       "      <td>935.000000</td>\n",
       "      <td>852.000000</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>741.000000</td>\n",
       "      <td>935.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>468.00000</td>\n",
       "      <td>957.945455</td>\n",
       "      <td>43.929412</td>\n",
       "      <td>101.282353</td>\n",
       "      <td>35.744385</td>\n",
       "      <td>13.468449</td>\n",
       "      <td>11.563636</td>\n",
       "      <td>7.234225</td>\n",
       "      <td>33.080214</td>\n",
       "      <td>0.893048</td>\n",
       "      <td>0.128342</td>\n",
       "      <td>0.341176</td>\n",
       "      <td>0.717647</td>\n",
       "      <td>2.941176</td>\n",
       "      <td>2.276995</td>\n",
       "      <td>10.682614</td>\n",
       "      <td>10.217274</td>\n",
       "      <td>6.779004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>270.05555</td>\n",
       "      <td>404.360822</td>\n",
       "      <td>7.224256</td>\n",
       "      <td>15.052636</td>\n",
       "      <td>7.638788</td>\n",
       "      <td>2.196654</td>\n",
       "      <td>4.374586</td>\n",
       "      <td>5.075206</td>\n",
       "      <td>3.107803</td>\n",
       "      <td>0.309217</td>\n",
       "      <td>0.334650</td>\n",
       "      <td>0.474358</td>\n",
       "      <td>0.450385</td>\n",
       "      <td>2.306254</td>\n",
       "      <td>1.595613</td>\n",
       "      <td>2.849756</td>\n",
       "      <td>3.300700</td>\n",
       "      <td>0.421144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.744932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>234.50000</td>\n",
       "      <td>669.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.505783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>468.00000</td>\n",
       "      <td>905.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.807935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>701.50000</td>\n",
       "      <td>1160.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>7.056175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>935.00000</td>\n",
       "      <td>3078.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>8.032035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0         wage       hours          IQ         KWW  \\\n",
       "count   935.00000   935.000000  935.000000  935.000000  935.000000   \n",
       "mean    468.00000   957.945455   43.929412  101.282353   35.744385   \n",
       "std     270.05555   404.360822    7.224256   15.052636    7.638788   \n",
       "min       1.00000   115.000000   20.000000   50.000000   12.000000   \n",
       "25%     234.50000   669.000000   40.000000   92.000000   31.000000   \n",
       "50%     468.00000   905.000000   40.000000  102.000000   37.000000   \n",
       "75%     701.50000  1160.000000   48.000000  112.000000   41.000000   \n",
       "max     935.00000  3078.000000   80.000000  145.000000   56.000000   \n",
       "\n",
       "             educ       exper      tenure         age     married       black  \\\n",
       "count  935.000000  935.000000  935.000000  935.000000  935.000000  935.000000   \n",
       "mean    13.468449   11.563636    7.234225   33.080214    0.893048    0.128342   \n",
       "std      2.196654    4.374586    5.075206    3.107803    0.309217    0.334650   \n",
       "min      9.000000    1.000000    0.000000   28.000000    0.000000    0.000000   \n",
       "25%     12.000000    8.000000    3.000000   30.000000    1.000000    0.000000   \n",
       "50%     12.000000   11.000000    7.000000   33.000000    1.000000    0.000000   \n",
       "75%     16.000000   15.000000   11.000000   36.000000    1.000000    0.000000   \n",
       "max     18.000000   23.000000   22.000000   38.000000    1.000000    1.000000   \n",
       "\n",
       "            south       urban        sibs     brthord       meduc       feduc  \\\n",
       "count  935.000000  935.000000  935.000000  852.000000  857.000000  741.000000   \n",
       "mean     0.341176    0.717647    2.941176    2.276995   10.682614   10.217274   \n",
       "std      0.474358    0.450385    2.306254    1.595613    2.849756    3.300700   \n",
       "min      0.000000    0.000000    0.000000    1.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    1.000000    1.000000    8.000000    8.000000   \n",
       "50%      0.000000    1.000000    2.000000    2.000000   12.000000   10.000000   \n",
       "75%      1.000000    1.000000    4.000000    3.000000   12.000000   12.000000   \n",
       "max      1.000000    1.000000   14.000000   10.000000   18.000000   18.000000   \n",
       "\n",
       "            lwage  \n",
       "count  935.000000  \n",
       "mean     6.779004  \n",
       "std      0.421144  \n",
       "min      4.744932  \n",
       "25%      6.505783  \n",
       "50%      6.807935  \n",
       "75%      7.056175  \n",
       "max      8.032035  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>wage</th>\n",
       "      <th>hours</th>\n",
       "      <th>IQ</th>\n",
       "      <th>KWW</th>\n",
       "      <th>educ</th>\n",
       "      <th>exper</th>\n",
       "      <th>tenure</th>\n",
       "      <th>age</th>\n",
       "      <th>married</th>\n",
       "      <th>black</th>\n",
       "      <th>south</th>\n",
       "      <th>urban</th>\n",
       "      <th>sibs</th>\n",
       "      <th>brthord</th>\n",
       "      <th>meduc</th>\n",
       "      <th>feduc</th>\n",
       "      <th>lwage</th>\n",
       "      <th>wage2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>769</td>\n",
       "      <td>40</td>\n",
       "      <td>93</td>\n",
       "      <td>35</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.645091</td>\n",
       "      <td>低</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>808</td>\n",
       "      <td>50</td>\n",
       "      <td>119</td>\n",
       "      <td>41</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.694562</td>\n",
       "      <td>低</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>825</td>\n",
       "      <td>40</td>\n",
       "      <td>108</td>\n",
       "      <td>46</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.715384</td>\n",
       "      <td>低</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>650</td>\n",
       "      <td>40</td>\n",
       "      <td>96</td>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.476973</td>\n",
       "      <td>低</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>562</td>\n",
       "      <td>40</td>\n",
       "      <td>74</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.331502</td>\n",
       "      <td>低</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  wage  hours   IQ  KWW  educ  exper  tenure  age  married  \\\n",
       "0           1   769     40   93   35    12     11       2   31        1   \n",
       "1           2   808     50  119   41    18     11      16   37        1   \n",
       "2           3   825     40  108   46    14     11       9   33        1   \n",
       "3           4   650     40   96   32    12     13       7   32        1   \n",
       "4           5   562     40   74   27    11     14       5   34        1   \n",
       "\n",
       "   black  south  urban  sibs  brthord  meduc  feduc     lwage wage2  \n",
       "0      0      0      1     1      2.0    8.0    8.0  6.645091     低  \n",
       "1      0      0      1     1      NaN   14.0   14.0  6.694562     低  \n",
       "2      0      0      1     1      2.0   14.0   14.0  6.715384     低  \n",
       "3      0      0      1     4      3.0   12.0   12.0  6.476973     低  \n",
       "4      0      0      1    10      6.0    6.0   11.0  6.331502     低  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info['wage2'] = info['wage'].apply(lambda x:'高' if x>905 else '低')\n",
    "info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_fea_name,con_fea_name,y_lable=['married','south'],['age','IQ','educ','tenure','wage','meduc','feduc'],['black','urban']\n",
    "sam_num,fea_num=info.shape[0],info.shape[1]-2#为什么不减一？因为取了两列当作标签啊\n",
    "\n",
    "#married，south分别表示是否结婚，是否来自南方，1均表示肯定\n",
    "#age,IQ,educ,tenure,wage,meduc,feduc分别表示年龄，智商，受教育时间，工作时间，工资，母亲受教育程度，父亲受教育程度\n",
    "#black,urban表示是否是黑人，是否住在城市，1均表示肯定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以还是如同上面的套路，代码都是类似的。然而机器学习虽然很多时候做法显得很粗暴：不管是否该参数在经济学上是否真的有能够影响因变量的逻辑（就如来自南方北方至少理论上不应该代表你因此成为黑人而且还能住在城市），但之所以实际能这么做是因为这些计算出来的先验概率将不会对后验概率的大小产生多大影响。因为从算法上能如此进行一步一步赋分是因为先验概率和后验概率不断迭代的结果：添加一个条件得到一个后验概率，然后把后验概率放入之前的先验概率再添加一个条件如此往复循环。但是，一定是先有逻辑上的假设，才抽样做验证，这个是任何社会科学统计研究都不能改变的顺序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_prob(dis_fea_name,con_fea_name,y_lable,laplacian=False):\n",
    "    #先计算我们的先验概率\n",
    "    labels_1=info[y_lable[0]]\n",
    "    labels_2=info[y_lable[2]]\n",
    "    for label_1 in labels_1:\n",
    "        for label_2 in labels_2:\n",
    "            lable1_num=labels_1.unique()\n",
    "            label2_num=labels_2.unique()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 真正的贝叶斯在金融中的一点应用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有一些股票在股票名称冠以st，这一类股票表示特别处理股票（实际上还有其他的前缀），st的意思是：公司连续两年亏损，特别处理\n",
    "\n",
    "st股表示着经营问题，但是这个经营问题我们并不知道是暂时性的问题（一般可以解决），还是一个商业模式或者商业信用的根本问题（那这个往往可能就会导致退市）。那么基于这个逻辑我们就思考一个问题：这个st股如果是前面的情况，根据中国股市的交易规则，总有做多股票的机会，而那些有这根本问题的股票，最后很可能就会退市。所以我们据此逻辑，来预测股票是否有价格被低估的可能。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import baostock as bs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "login success!\n"
     ]
    }
   ],
   "source": [
    "lg=bs.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_list=random.sample(range(600100,600999),500)\n",
    "def sto_samp():\n",
    "    data_dict={}\n",
    "    for i in range(500):\n",
    "        rs=bs.query_history_k_data_plus('sh.'+str(stock_list[i]),\"code,volume,amount,turn,pctChg,tradestatus,isST\")\n",
    "        while rs.error_code=='0':\n",
    "            data_dict[i]=rs.get_row_data()\n",
    "            for k in list(data.keys()):\n",
    "                if not data_dict[k] :\n",
    "                    del data_dict[k]\n",
    "                    result=pd.DataFrame(data_dict,columns=rs.fields)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-ed3d5efa79ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m         \u001b[0mrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery_history_k_data_plus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sh.'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstock_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"code,volume,amount,turn,pctChg,tradestatus,isST\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_code\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'0'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m             \u001b[0mdata_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_row_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_dict' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(500):\n",
    "        rs=bs.query_history_k_data_plus('sh.'+str(stock_list[i]),\"code,volume,amount,turn,pctChg,tradestatus,isST\")\n",
    "        while rs.error_code=='0':\n",
    "            data_dict[i]=rs.get_row_data()\n",
    "            for k in list(data_dict.keys()):\n",
    "                if not data_dict[k]:\n",
    "                    del data_dict[k]\n",
    "                    result=pd.DataFrame(data_dict,columns=rs.fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs=bs.query_history_k_data_plus('sh.'+str(stock_list[i]),\"code,volume,amount,turn,pctChg,tradestatus,isST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sh.600392', '12676796', '376181712.0000', '8.095017', '-2.751400', '1', '0']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.get_row_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
